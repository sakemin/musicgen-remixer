{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicGen Remixer\n",
    "### Remix the music into another styles with MusicGen Chord\n",
    "[MusicGen Remixer](https://replicate.com/sakemin/musicgen-remixer) is an app based on MusicGen Chord. Users can upload a music track with vocals, type in the text description prompt, and the app will create a new background track based on the input and then make a remixed music output.\n",
    "This Jupyter notebook breaks down the process of MusicGen Remixer, by calling separate Replicate API calls and processing the outputs of the API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Replicate client & python packages with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install replicate numpy pydub requests scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate Replicate API token\n",
    "Run the cell below and type in your Replicate token. You can check your token [here](https://replicate.com/account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "from pathlib import Path\n",
    "import urllib.request, json\n",
    "import numpy as np\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "from scipy.signal import resample\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_and_load_as_numpy(url):\n",
    "    \"\"\"\n",
    "    Downloads an audio file (MP3 or WAV) from a given URL and loads it into a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the audio file to download.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The audio data as a NumPy array.\n",
    "    int: The sample rate of the audio file.\n",
    "    \"\"\"\n",
    "    # Download the audio file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Read the audio file as a byte stream\n",
    "    audio_file = BytesIO(response.content)\n",
    "\n",
    "    # Determine the file format from the URL\n",
    "    file_format = url.split(\".\")[-1].lower()\n",
    "\n",
    "    # Load the audio file using pydub\n",
    "    if file_format == \"mp3\":\n",
    "        audio = AudioSegment.from_mp3(audio_file)\n",
    "    elif file_format == \"wav\":\n",
    "        audio = AudioSegment.from_wav(audio_file)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format: only MP3 and WAV are supported.\")\n",
    "\n",
    "    # Convert the audio to a NumPy array with a channel dimension\n",
    "    channel_count = audio.channels\n",
    "    audio_data = np.array(audio.get_array_of_samples())\n",
    "    if channel_count == 2:\n",
    "        audio_data = audio_data.reshape(-1, 2)\n",
    "    else:\n",
    "        audio_data = audio_data.reshape(-1, 1)\n",
    "\n",
    "    return audio_data, audio.frame_rate\n",
    "\n",
    "\n",
    "def save_numpy_as_audio(audio_data, sample_rate, output_filename):\n",
    "    \"\"\"\n",
    "    Saves a NumPy array as an audio file (MP3 or WAV).\n",
    "\n",
    "    Parameters:\n",
    "    audio_data (np.ndarray): The audio data to save.\n",
    "    sample_rate (int): The sample rate of the audio data.\n",
    "    output_filename (str): The name of the output file.\n",
    "    \"\"\"\n",
    "    # Determine the file format from the output filename\n",
    "    file_format = output_filename.split(\".\")[-1].lower()\n",
    "\n",
    "    # Normalize audio\n",
    "    audio_data = normalize_audio(audio_data)\n",
    "\n",
    "    # Determine the number of channels based on the shape of the audio data\n",
    "    channels = audio_data.shape[1] if audio_data.ndim > 1 else 1\n",
    "\n",
    "    # Convert the NumPy array to an AudioSegment\n",
    "    audio_segment = AudioSegment(\n",
    "        audio_data.tobytes(),\n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=audio_data.dtype.itemsize,\n",
    "        channels=channels,\n",
    "    )\n",
    "\n",
    "    # Export the AudioSegment as an audio file\n",
    "    audio_segment.export(output_filename, format=file_format)\n",
    "\n",
    "\n",
    "def resample_audio(audio_data, original_sample_rate, new_sample_rate):\n",
    "    \"\"\"\n",
    "    Resamples the audio data to a new sample rate.\n",
    "\n",
    "    Parameters:\n",
    "    audio_data (np.ndarray): The audio data to resample.\n",
    "    original_sample_rate (int): The original sample rate of the audio data.\n",
    "    new_sample_rate (int): The new sample rate to resample to.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The resampled audio data.\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples in the resampled audio\n",
    "    num_original_samples = audio_data.shape[0]\n",
    "    resample_ratio = new_sample_rate / original_sample_rate\n",
    "    num_new_samples = int(num_original_samples * resample_ratio)\n",
    "\n",
    "    # Resample the audio data\n",
    "    resampled_audio = resample(audio_data, num_new_samples)\n",
    "\n",
    "    return resampled_audio\n",
    "\n",
    "\n",
    "def normalize_audio(audio_data):\n",
    "    \"\"\"\n",
    "    Normalizes the audio data in a NumPy array to a range of -1 to 1.\n",
    "\n",
    "    Parameters:\n",
    "    audio_data (np.ndarray): The audio data to normalize.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The normalized audio data.\n",
    "    \"\"\"\n",
    "    # Find the maximum absolute value in the audio data\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "\n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    normalized_audio = audio_data / max_val\n",
    "\n",
    "    # Scale to int16 range and convert\n",
    "    max_int16 = np.iinfo(np.int16).max\n",
    "    normalized_audio_scaled = np.clip(\n",
    "        normalized_audio * max_int16, -max_int16, max_int16\n",
    "    ).astype(np.int16)\n",
    "\n",
    "    return normalized_audio_scaled\n",
    "\n",
    "\n",
    "def mix_audio_volumes(audio1, audio2, weight1=0.5, weight2=0.5):\n",
    "    \"\"\"\n",
    "    Mixes two audio numpy arrays with given weights to ensure even volume.\n",
    "\n",
    "    Parameters:\n",
    "    audio1 (np.ndarray): The first audio data to mix.\n",
    "    audio2 (np.ndarray): The second audio data to mix.\n",
    "    weight1 (float): The weight for the first audio data.\n",
    "    weight2 (float): The weight for the second audio data.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The mixed audio data.\n",
    "    \"\"\"\n",
    "    if audio1.shape != audio2.shape:\n",
    "        raise ValueError(\"Both audio arrays must have the same shape\")\n",
    "\n",
    "    # Normalize each audio array\n",
    "    audio1_normalized = audio1 / np.max(np.abs(audio1))\n",
    "    audio2_normalized = audio2 / np.max(np.abs(audio2))\n",
    "\n",
    "    # Apply weights and mix\n",
    "    mixed_audio = (audio1_normalized * weight1) + (audio2_normalized * weight2)\n",
    "    mixed_audio_normalized = mixed_audio / np.max(np.abs(mixed_audio))\n",
    "\n",
    "    # Scale to int16 range and convert\n",
    "    max_int16 = np.iinfo(np.int16).max\n",
    "    mixed_audio_scaled = np.clip(mixed_audio * max_int16, -max_int16, max_int16).astype(\n",
    "        np.int16\n",
    "    )\n",
    "\n",
    "    return mixed_audio_scaled\n",
    "\n",
    "\n",
    "def int16_scale(audio):\n",
    "    # Scale to int16 range and convert\n",
    "    max_int16 = np.iinfo(np.int16).max\n",
    "    audio_scaled = np.clip(audio * max_int16, -max_int16, max_int16).astype(np.int16)\n",
    "\n",
    "    return audio_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<your prompt>\"\n",
    "audio_path = \"/your/audio/input.mp3\"  # mp3 or wav\n",
    "model_version = \"chord\"  # chord, chord-large, stereo-chord, stereo-chord-large\n",
    "beat_sync_threshold = (\n",
    "    None  # 0.75 is a good value, when `None`, automatically set to `1.1/(bpm/60)`\n",
    ")\n",
    "output_path = \"output\"\n",
    "upscale = False  # Whether to upscale the audio to 48kHz with AudioSR\n",
    "mix_weight = 0.7  # The weight for the generated instrumental track when mixing with the vocal.(0~1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "(Path(output_path) / \"inter_process\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"stereo\" in model_version:\n",
    "    channel = 2\n",
    "else:\n",
    "    channel = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get BPM and downbeat analysis of input audio, using [All-In-One Music Structure Analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analysis_url = replicate.run(\n",
    "    \"sakemin/all-in-one-music-structure-analyzer:001b4137be6ac67bdc28cb5cffacf128b874f530258d033de23121e785cb7290\",\n",
    "    input={\"music_input\": Path(audio_path)},\n",
    ")\n",
    "\n",
    "time_analysis_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the output JSON and get BPM and downbeat values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(time_analysis_url[0]) as url:\n",
    "    data = json.load(url)\n",
    "\n",
    "time_analysis = data\n",
    "\n",
    "bpm = time_analysis[\"bpm\"]\n",
    "input_downbeats = time_analysis[\"downbeats\"]\n",
    "\n",
    "print(\"BPM:\", bpm)\n",
    "print(\"Downbeats:\", input_downbeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `beat_sync_threshold` when it is `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not beat_sync_threshold or beat_sync_threshold == -1:\n",
    "    if bpm is not None:\n",
    "        beat_sync_threshold = 1.1 / (int(bpm) / 60)\n",
    "    else:\n",
    "        beat_sync_threshold = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate vocal track out of instrumental track, using [Demucs](https://replicate.com/cjwbw/demucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_urls = replicate.run(\n",
    "    \"cjwbw/demucs:25a173108cff36ef9f80f854c162d01df9e6528be175794b81158fa03836d953\",\n",
    "    input={\n",
    "        \"audio\": Path(audio_path),\n",
    "        \"stem\": \"vocals\",\n",
    "        \"shifts\": 2,  # higher values for better quality, but takes more time\n",
    "        \"float32\": True,\n",
    "        \"output_format\": \"mp3\",\n",
    "    },\n",
    ")\n",
    "\n",
    "track_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the separated vocal track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_track, vocal_sr = download_audio_and_load_as_numpy(track_urls[\"vocals\"])\n",
    "vocal_sr, vocal_track.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the vocal track in mp3 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_path = (\n",
    "    str(Path(output_path) / \"inter_process\" / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + \"_vocals.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(vocal_track, vocal_sr, vocal_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the separated instrumental track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumental_track, instrumental_sr = download_audio_and_load_as_numpy(\n",
    "    track_urls[\"other\"]\n",
    ")\n",
    "instrumental_sr, instrumental_track.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the instrumental track in mp3 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumental_path = (\n",
    "    str(Path(output_path) / \"inter_process\" / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + \"_inst.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(instrumental_track, instrumental_sr, instrumental_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a new instrumental track with the prompt and the original instrumental track as input, using [MusicGen-Stereo-Chord](https://replicate.com/sakemin/musicgen-stereo-chord)\n",
    "### This might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_instrumental_url = replicate.run(\n",
    "    \"sakemin/musicgen-stereo-chord:fbdc5ef7200220ed300015d9b4fd3f8e620f84547e970b23aa2be7f2ff366a5b\",\n",
    "    input={\n",
    "        \"model_version\": model_version,\n",
    "        \"prompt\": prompt + \", bpm: \" + str(bpm),\n",
    "        \"audio_chords\": Path(instrumental_path),\n",
    "        \"duration\": int(instrumental_track.shape[0] / instrumental_sr),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(generated_instrumental_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the generated instrumental track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    generated_instrumental_track,\n",
    "    generated_instrumental_sr,\n",
    ") = download_audio_and_load_as_numpy(generated_instrumental_url)\n",
    "generated_instrumental_sr, generated_instrumental_track.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the generated instrumental track in mp3 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_instrumental_path = (\n",
    "    str(Path(output_path) / \"inter_process\" / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + f\"_{prompt}\"\n",
    "    + \"_generated_inst.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(\n",
    "    generated_instrumental_track, generated_instrumental_sr, generated_instrumental_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample rate matching(Choose one of the 2 options below)\n",
    "- Choose one of the two ways given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Force upsample the generated track to the input sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not upscale:\n",
    "    resampled_instrumental_track = resample_audio(\n",
    "        generated_instrumental_track, generated_instrumental_sr, vocal_sr\n",
    "    )\n",
    "    resampled_instrumental_track = int16_scale(\n",
    "        normalize_audio(resampled_instrumental_track)\n",
    "    )\n",
    "    print(resampled_instrumental_track.shape, vocal_track.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upscale the tracks to 48khz with [Audio-Super-Resolution](https://replicate.com/sakemin/audiosr-long-audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if upscale:\n",
    "    resampled_instrumental_url = replicate.run(\n",
    "        \"sakemin/audiosr-long-audio:44b37256d8d2ade24655f05a0d35128642ca90cbad0f5fa0e9bfa2d345124c8c\",\n",
    "        input={\"input_file\": Path(generated_instrumental_path)},\n",
    "    )\n",
    "    print(resampled_instrumental_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if upscale:\n",
    "    (\n",
    "        resampled_instrumental_track,\n",
    "        resampled_instrumental_sr,\n",
    "    ) = download_audio_and_load_as_numpy(resampled_instrumental_url)\n",
    "    print(resampled_instrumental_sr, resampled_instrumental_track.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if upscale:\n",
    "    resampled_vocal_url = replicate.run(\n",
    "        \"sakemin/audiosr-long-audio:44b37256d8d2ade24655f05a0d35128642ca90cbad0f5fa0e9bfa2d345124c8c\",\n",
    "        input={\"input_file\": Path(vocal_path)},\n",
    "    )\n",
    "    print(resampled_vocal_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not upscale:\n",
    "    vocal_track, vocal_sr = download_audio_and_load_as_numpy(resampled_vocal_url)\n",
    "    print(vocal_sr, vocal_track.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the resampled instrumental track in mp3 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_instrumental_path = (\n",
    "    str(Path(output_path) / \"inter_process\" / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + f\"_{prompt}\"\n",
    "    + \"_resampled_inst.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(resampled_instrumental_track, vocal_sr, resampled_instrumental_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beat synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get BPM and downbeat analysis of generated audio, using [All-In-One Music Structure Analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_time_analysis_url = replicate.run(\n",
    "    \"sakemin/all-in-one-music-structure-analyzer:001b4137be6ac67bdc28cb5cffacf128b874f530258d033de23121e785cb7290\",\n",
    "    input={\"music_input\": Path(resampled_instrumental_path)},\n",
    ")\n",
    "\n",
    "output_time_analysis_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the output JSON and get downbeat value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(output_time_analysis_url[0]) as url:\n",
    "    data = json.load(url)\n",
    "\n",
    "output_time_analysis = data\n",
    "\n",
    "generated_downbeats = output_time_analysis[\"downbeats\"]\n",
    "\n",
    "print(\"Downbeats:\", generated_downbeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the downbeats pair-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_generated_downbeats = []\n",
    "aligned_input_downbeats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for generated_downbeat in generated_downbeats:\n",
    "    input_beat = min(\n",
    "        input_downbeats, key=lambda x: abs(generated_downbeat - x), default=None\n",
    "    )\n",
    "    if input_beat is None:\n",
    "        continue\n",
    "    print(generated_downbeat, input_beat)\n",
    "    if (\n",
    "        len(aligned_input_downbeats) != 0\n",
    "        and int(input_beat * vocal_sr) == aligned_input_downbeats[-1]\n",
    "    ):\n",
    "        print(\"Dropped\")\n",
    "        continue\n",
    "    if abs(generated_downbeat - input_beat) > beat_sync_threshold:\n",
    "        input_beat = generated_downbeat\n",
    "        print(\"Replaced\")\n",
    "    aligned_generated_downbeats.append(int(generated_downbeat * vocal_sr))\n",
    "    aligned_input_downbeats.append(int(input_beat * vocal_sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_length = resampled_instrumental_track.shape[-2]\n",
    "downbeat_offset = aligned_input_downbeats[0] - aligned_generated_downbeats[0]\n",
    "if downbeat_offset > 0:\n",
    "    resampled_instrumental_track = np.concatenate(\n",
    "        [np.zeros([1, channel, int(downbeat_offset)]), resampled_instrumental_track],\n",
    "        dim=-1,\n",
    "    )\n",
    "    for i in range(len(aligned_generated_downbeats)):\n",
    "        aligned_generated_downbeats[i] = (\n",
    "            aligned_generated_downbeats[i] + downbeat_offset\n",
    "        )\n",
    "aligned_generated_downbeats = [0] + aligned_generated_downbeats + [wav_length]\n",
    "aligned_input_downbeats = [0] + aligned_input_downbeats + [wav_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ap = \"\"\n",
    "for i in range(len(aligned_generated_downbeats) - 1):\n",
    "    s_ap += (\n",
    "        str(aligned_generated_downbeats[i])\n",
    "        + \":\"\n",
    "        + str(aligned_input_downbeats[i])\n",
    "        + \", \"\n",
    "    )\n",
    "s_ap += str(aligned_generated_downbeats[-1]) + \":\" + str(aligned_input_downbeats[-1])\n",
    "s_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply dynamic time-stretching on the generated instrumental track, using [PyTSMod](https://replicate.com/sakemin/pytsmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stretched_instrumental_track_url = replicate.run(\n",
    "    \"sakemin/pytsmod:41b355721c8a7ed501be7fd89e73631e7c07d75e1c94b1372c1c119b0774cdae\",\n",
    "    input={\n",
    "        \"audio_input\": Path(resampled_instrumental_path),\n",
    "        \"s_ap\": s_ap,\n",
    "        \"absolute_frame\": True,\n",
    "    },\n",
    ")\n",
    "time_stretched_instrumental_track_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the time-stretched instrumental track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    time_stretched_instrumental_track,\n",
    "    time_stretched_instrumental_sr,\n",
    ") = download_audio_and_load_as_numpy(time_stretched_instrumental_track_url)\n",
    "time_stretched_instrumental_sr, time_stretched_instrumental_track.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the time-stretched instrumental track in mp3 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stretched_instrumental_path = (\n",
    "    str(Path(output_path) / \"inter_process\" / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + f\"_{prompt}\"\n",
    "    + \"_time_stretched_inst.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(\n",
    "    time_stretched_instrumental_track,\n",
    "    time_stretched_instrumental_sr,\n",
    "    time_stretched_instrumental_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the generated instrumental track and the original vocal track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad the generated track's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = vocal_track.shape[0] - time_stretched_instrumental_track.shape[0]\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pad > 0:\n",
    "    padded_instrumental_track = np.pad(\n",
    "        time_stretched_instrumental_track, ((0, pad), (0, 0)), \"constant\"\n",
    "    )\n",
    "else:\n",
    "    padded_instrumental_track = time_stretched_instrumental_track[\n",
    "        : vocal_track.shape[0]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the number of channels consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if channel == 1 and vocal_track.shape[1] == 2:\n",
    "    padded_instrumental_track = np.repeat(padded_instrumental_track, 2, axis=1)\n",
    "if channel == 2 and vocal_track.shape[1] == 1:\n",
    "    vocal_track = np.repeat(vocal_track, 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix and normalize two tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_track = mix_audio_volumes(\n",
    "    padded_instrumental_track, vocal_track, weight1=mix_weight, weight2=1 - mix_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play the remixed track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(mixed_track.T, rate=time_stretched_instrumental_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the remixed track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remixed_path = (\n",
    "    str(Path(output_path) / Path(audio_path).name.rsplit(\".\", 1)[0])\n",
    "    + f\"_{prompt}\"\n",
    "    + \"_remixed.mp3\"\n",
    ")\n",
    "save_numpy_as_audio(mixed_track, time_stretched_instrumental_sr, remixed_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGen_Chord-VFGWlmB1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
